{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"I7Lr6ApC3IBG"},"outputs":[],"source":["from langchain_experimental.text_splitter import SemanticChunker\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","import aspose.words as aw\n","import os\n","import pdfminer\n","from unstructured.partition.pdf import partition_pdf\n","from unstructured.staging.base import elements_to_json\n","import pytesseract\n","os.environ['PATH'] += r';C:\\Program Files\\Tesseract-OCR' # dodajem tesseract u Path varijable\n","#C:\\Program Files\\Tesseract-OCR"]},{"cell_type":"markdown","metadata":{"id":"pLRkxPn_3IBH"},"source":["**Parsiranje pdf fajla u elemente pomocu partition_pdf, hi_res strategije i yolox modela. Elemente ćemo sačuvati u folder results/ da bi se mogle isprobavati različite strategije chunkovanja i veličine chunkova.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NA-P0cak3IBH"},"outputs":[],"source":["elements = partition_pdf(\n","    filename='../data/ISLP.pdf',  # putanja do pdf fajla\n","    strategy=\"hi_res\", # strategija za obradu pdf dokumenta\n","    infer_table_structure=True, # prepoznaje da u dokumentu postoji tabela i strukturira je\n","    model_name=\"yolox\", # model koji ćemo koristiti za prepoznavanje i analizu objekata u slikama\n","    extract_images_in_pdf=True, # omogucuje ekstrakciju slika iz pdf - a u folder figures/\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6P3QOqn3IBI"},"outputs":[],"source":["import pickle\n","with open(\"results/pdf_elements.pkl\",\"wb\") as file:\n","    pickle.dump(elements,file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DxcFpV843IBI"},"outputs":[],"source":["with open(\"results/pdf_elements.pkl\",\"rb\") as file:\n","    elements = pickle.load(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fl9WiKj03IBI","outputId":"2cd078fe-c718-4c87-9ed0-4e683ae09d25"},"outputs":[{"data":{"text/plain":["8555"]},"execution_count":153,"metadata":{},"output_type":"execute_result"}],"source":["len(elements)"]},{"cell_type":"markdown","metadata":{"id":"j7YtkuJ53IBJ"},"source":["**Vidimo da nisu svi elementi koji su Header/Footer prepoznati kao Header/Footer, vec da su mnogi Header/Footer elementi prepoznati kao elementi klase ListItem, pa je potrebno po sadržaju odrediti koji elementi remete grupisanje u chunkove. Zato će sadržaj svih ListItem, Header, Footer elemenata biti skladišten u .csv fajl da bi se istrenirao klasifikator koji prepoznaje po sadržaju da li je element Header/Footer ili regularni ListItem (bullet u nabrajanju).**"]},{"cell_type":"code","source":["import csv\n","\n","train_data = list()\n","for element in elements:\n","    if str(element.__class__.__name__)==\"Footer\" or str(element.__class__.__name__)=='Header' or str(element.__class__.__name__)==\"ListItem\":\n","        train_data.append({'text':element.text,'content_type':str(element.__class__.__name__),'junk':''})\n","        #print(element.text)\n","filename=\"../data/junk_classification.csv\"\n","with open(filename,mode='w',newline='',encoding='utf-8') as file:\n","    writer = csv.DictWriter(file,fieldnames=train_data[0].keys())\n","    writer.writeheader()\n","    writer.writerows(train_data)"],"metadata":{"id":"XTtk5mObL0LD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**U fajlu bert_for_text_classification nalazi se fine - tune - ovan bert-base uncased model**"],"metadata":{"id":"N3WCIpB7L9DK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-7q9z0t3IBJ"},"outputs":[],"source":["from bert_for_text_classification import load_model, predict_probabilities\n","\n","model, tokenizer =load_model()\n","predictions = predict_probabilities(\"1. Introduction 11\",model, tokenizer) # provera"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ORqOktep3IBK"},"outputs":[],"source":["model, tokenizer =load_model()\n","for element in elements:\n","    if str(element.__class__.__name__)=='Header' or str(element.__class__.__name__)=='Footer' or str(element.__class__.__name__)=='ListItem': #\n","        probs = predict_probabilities(element.text,model, tokenizer)\n","        if probs[0][1].float() > 0.5: # znaci da je u pitanju junk\n","            elements.remove(element)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZ5cvA5m3IBK","outputId":"55116963-3bb6-4238-ae95-b562d653cfaa"},"outputs":[{"data":{"text/plain":["7975"]},"execution_count":155,"metadata":{},"output_type":"execute_result"}],"source":["len(elements) # obrisano je 585 elemenata"]},{"cell_type":"markdown","source":["**Sačuvaćemo elemente koji su redukovani za Header / Footer sadržaj u odnosu na početni skup pdf elemenata.**"],"metadata":{"id":"eKZQ-cq3MbFs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GO64EqVh3IBK"},"outputs":[],"source":["with open(\"results/elements_without_header.pkl\",\"wb\") as file:\n","    pickle.dump(elements,file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4D0TVSCW3IBK"},"outputs":[],"source":["import pickle\n","with open(\"results/elements_without_header.pkl\",\"rb\") as file:\n","    elements = pickle.load(file)"]},{"cell_type":"markdown","source":["**Povezivanje tekstualnih elemenata u instance klase CompositeElement kao skup tekstualnih elemenata**"],"metadata":{"id":"pM6LBAhWM5rh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5aXuewFd3IBK"},"outputs":[],"source":["from unstructured.chunking.basic import chunk_elements\n","from unstructured.chunking.title import chunk_by_title\n","\n","\n","elements_chunk_by_title = chunk_by_title(elements,\n","                                         combine_text_under_n_chars=2500, # svi manji chunkovi od 1000 karaktera se kombinuju\n","                                         max_characters=4000, # maximalna velicina chunka\n","                                         multipage_sections=True,\n","                                         new_after_n_chars=3800, # ako je chunk veci od ovoga nece vise rasti do 1500\n","                                         overlap=True,\n","                                         #ovde je text separator by title, tj. \\n\\n, samim tim ne postoji ova opcija da se doda\n","                                         )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezgIBnlk3IBK"},"outputs":[],"source":["with open(\"results/chunking_strategy_4/chunked_elements.pkl\",\"wb\") as file:\n","    pickle.dump(elements_chunk_by_title,file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8FegxBaI3IBK"},"outputs":[],"source":["elements_after_chunking =  chunk_elements(elements,       # ostavljen je prostor za drge strategije chunk - ovanja\n","                                          max_characters=8000,\n","                                          new_after_n_chars=7800,\n","                                          )"]},{"cell_type":"markdown","source":["**U sledećoj ćeliji nalazi se celokupni kod ubačen u jednu funkciju**"],"metadata":{"id":"CQF03bmYNatL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfXd_Hul3IBL"},"outputs":[],"source":["def parse_pdf():\n","    # ekstrakcija teksta\n","    elements = partition_pdf(\n","        filename='../data/ISLP.pdf',  # putanja do pdf fajla\n","        strategy=\"hi_res\", # strategija za obradu pdf dokumenta\n","        infer_table_structure=True, # prepoznaje da u dokumentu postoji tabela i strukturira je\n","        model_name=\"yolox\", # model koji ćemo koristiti za prepoznavanje i analizu objekata u slikama\n","        extract_images_in_pdf=True,\n","        )\n","\n","\n","    #eliminacija headera i footera\n","    model, tokenizer =load_model()\n","    for element in elements:\n","        if str(element.__class__.__name__)=='Header' or str(element.__class__.__name__)=='Footer' or str(element.__class__.__name__)=='ListItem':\n","            probs = predict_probabilities(element.text,model, tokenizer)\n","        if probs[0][1].float() > 0.5: # znaci da je u pitanju junk\n","            elements.remove(element) # znaci da je pobrkao title sa headerom\n","\n","\n","    #chunkovanje\n","    elements_chunk_by_title = chunk_by_title(elements,\n","                                            combine_text_under_n_chars=1000, # svi manji chunkovi od 7500 karaktera se kombinuju\n","                                            max_characters=1600, # maximalna velicina chunka\n","                                            multipage_sections=True,\n","                                            new_after_n_chars=1200, # ako je chunk veci od ovoga nece vise rasti do 8000\n","                                            overlap=True,\n","                                            #ovde je text separator by title, tj. \\n\\n, samim tim ne postoji ova opcija da se doda\n","                                            )\n","    return elements_chunk_by_title"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUBIYa4A3IBL","outputId":"ee00a9ac-217d-4c72-c8d7-cb4a09f6e22c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n","- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["chunks = parse_pdf()"]}],"metadata":{"kernelspec":{"display_name":"Python (virtual_environment)","language":"python","name":"virtual_environment"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}