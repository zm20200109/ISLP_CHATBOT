{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"5Gm-wWqFmo9X","outputId":"6633eac9-a90c-4859-8920-77a875d75ec0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ragatouille in /usr/local/lib/python3.10/dist-packages (0.0.8.post4)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.2)\n","Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.3.10)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.3)\n","Requirement already satisfied: colbert-ai==0.2.19 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.2.19)\n","Requirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (1.9.0)\n","Requirement already satisfied: fast-pytorch-kmeans==0.2.0.1 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.2.0.1)\n","Requirement already satisfied: llama-index>=0.7 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.11.18)\n","Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (1.17.0)\n","Requirement already satisfied: sentence-transformers<3.0.0,>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.7.0)\n","Requirement already satisfied: srsly==2.4.8 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.4.8)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.4.1+cu121)\n","Requirement already satisfied: transformers<5.0.0,>=4.36.2 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (4.44.2)\n","Requirement already satisfied: voyager<3.0.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.0.9)\n","Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (3.0.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (3.0.1)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (2.2.5)\n","Requirement already satisfied: git-python in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.0.3)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.0.1)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.11.1.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.13.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (4.66.5)\n","Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (5.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fast-pytorch-kmeans==0.2.0.1->ragatouille) (1.26.4)\n","Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from fast-pytorch-kmeans==0.2.0.1->ragatouille) (11.5.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from srsly==2.4.8->ragatouille) (2.0.10)\n","Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.51.2)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.8.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (0.1.135)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.0)\n","Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.3.4)\n","Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.3.1)\n","Requirement already satisfied: llama-index-core<0.12.0,>=0.11.18 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.11.18)\n","Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.2.5)\n","Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.4.0)\n","Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.9.48.post3)\n","Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.2.14)\n","Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.2.2)\n","Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.2.0)\n","Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.2.0)\n","Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.2.2)\n","Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (0.3.0)\n","Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.7->ragatouille) (3.9.1)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (3.20.3)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.6.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.5.2)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.24.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (10.4.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (3.16.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (2024.6.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.19.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (0.14.0)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.18->llama-index>=0.7->ragatouille) (0.6.7)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.18->llama-index>=0.7->ragatouille) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.18->llama-index>=0.7->ragatouille) (1.0.8)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.18->llama-index>=0.7->ragatouille) (1.6.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.18->llama-index>=0.7->ragatouille) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.18->llama-index>=0.7->ragatouille) (1.16.0)\n","Requirement already satisfied: llama-cloud>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index>=0.7->ragatouille) (0.1.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index>=0.7->ragatouille) (2.2.2)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index>=0.7->ragatouille) (4.12.3)\n","Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index>=0.7->ragatouille) (4.3.1)\n","Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index>=0.7->ragatouille) (0.0.26)\n","Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index>=0.7->ragatouille) (0.5.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index>=0.7->ragatouille) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index>=0.7->ragatouille) (1.4.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.70.16)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (3.0.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (2.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->ragatouille) (3.0.1)\n","Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (from git-python->colbert-ai==0.2.19->ragatouille) (3.1.43)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->ragatouille) (1.3.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index>=0.7->ragatouille) (2.6)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.18->llama-index>=0.7->ragatouille) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.18->llama-index>=0.7->ragatouille) (3.22.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython->git-python->colbert-ai==0.2.19->ragatouille) (4.0.11)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index>=0.7->ragatouille) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index>=0.7->ragatouille) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index>=0.7->ragatouille) (2024.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille) (5.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index>=0.7->ragatouille) (1.16.0)\n"]}],"source":["!pip install ragatouille langchain-openai langchain-core langchain"]},{"cell_type":"code","source":["import pandas as pd\n","from langchain_core.prompts import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n","from langchain_core.prompts import PromptTemplate\n","from langchain_openai.chat_models import ChatOpenAI\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","import os\n","from dotenv import load_dotenv\n","load_dotenv()\n","\n","\n","dataset = pd.read_csv(\"/content/formulas_dataset (1).csv\")\n","\n","# examples\n","filtered_dataset = dataset.loc[dataset[\"upgraded_answer\"].isna()==False]\n","\n","# need to be filled\n","nan_upgraded_answer = dataset.loc[dataset[\"upgraded_answer\"].isna()==True]\n","\n","template = \"\"\" Your task is to create appropriate question based on the provided context and formula, where the answer of the created question is going to be provided formula.\n","\"\"\"\n","\n","examples = [{\"context\":element[\"text_chunk\"],\"formula\":element[\"formula_summary\"],\"question\":element[\"question\"],} for element in filtered_dataset.to_dict(orient=\"records\")]\n","\n","\n","examples_for_fsp = [{\"input\":f\"\"\"Context:\\n{dictionary[\"context\"]}\\nFormula:{dictionary[\"formula\"]}\"\"\",\"output\":dictionary[\"question\"]} for dictionary in examples]\n","\n","\n","example_prompt = ChatPromptTemplate.from_messages(\n","    [\n","      (\"human\",\"{input}\"),\n","      (\"ai\",\"{output}\"),\n","    ]\n",")\n","\n","few_shot_prompt = FewShotChatMessagePromptTemplate(\n","    examples=examples_for_fsp,\n","    example_prompt=example_prompt,\n",")\n","\n","\n","final_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",template),\n","        few_shot_prompt,\n","        (\"human\",\"{input}\"),\n","    ]\n",")\n","\n","\n","OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n","\n","chat = ChatOpenAI(temperature=0, api_key=OPENAI_API_KEY)\n","\n","chain = final_prompt | chat | StrOutputParser()\n","\n","questions = [chain.invoke({\"input\":f\"\"\"Context:\\n{dictionary[\"text_chunk\"]}\\nFormula:{dictionary[\"formula_summary\"]}\"\"\"}) for dictionary in nan_upgraded_answer.to_dict(orient=\"records\")]\n"],"metadata":{"id":"sdFfLg0oYqRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions_for_new_formulas = pd.concat([nan_upgraded_answer.reset_index(drop=True), pd.Series(questions,name=\"new_questions\")],axis=1) # pitanja koja je generisao model"],"metadata":{"id":"Eee1xi-kHCxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["template_qa = \"\"\"Your task is to create concatenation of question and answer based on the provided question and answer. The answer is provided as the mathematical formula\n","which gives an answer of the provided question.\n","\"\"\"\n","\n","examples_for_q_a_concatenation = [{\"input\":f\"\"\"Question:{dictionary[\"question\"]}\\nFormula:{dictionary[\"formula_summary\"]}\"\"\",\"output\":dictionary[\"upgraded_answer\"]} for dictionary in filtered_dataset.to_dict(orient=\"records\")]\n","\n","examples_for_qa_concatenation_prompt = ChatPromptTemplate.from_messages(\n","                                          [\n","                                            (\"human\",\"{input}\"),\n","                                            (\"ai\",\"{output}\"),\n","                                          ]\n","                                       )\n","few_shot_prompt_qa = FewShotChatMessagePromptTemplate(\n","      examples=examples_for_q_a_concatenation,\n","      example_prompt=examples_for_qa_concatenation_prompt,\n","  )\n","\n","final_prompt_q_a = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",template_qa),\n","        few_shot_prompt_qa,\n","        (\"human\",\"{input}\"),\n","    ]\n",")\n","\n","OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n","\n","chat = ChatOpenAI(temperature=0, api_key=OPENAI_API_KEY)\n","\n","chain_qa = final_prompt_q_a | chat | StrOutputParser()\n","\n","upgraded_answers = [chain_qa.invoke({\"input\":f\"\"\"Question:\\n{dictionary[\"question\"]}\\nFormula:{dictionary[\"formula_summary\"]}\"\"\"}) for dictionary in questions_for_new_formulas.to_dict(orient=\"records\")]\n"],"metadata":{"id":"Kl7VVKsjIOvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_dataset = pd.concat([questions_for_new_formulas[[\"new_questions\"]].reset_index(drop=True),pd.Series(upgraded_answers,name=\"answer\")], axis=1)\n","result_dataset.columns = [\"question\", \"answer\"]"],"metadata":{"id":"jEftkQPPKFuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_few_shot_examples = filtered_dataset[[\"question\",\"upgraded_answer\"]]\n","original_few_shot_examples.columns = [\"question\",\"answer\"]"],"metadata":{"id":"1onHIlHsQstn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_for_model = pd.concat([original_few_shot_examples.reset_index(drop=True), result_dataset.reset_index(drop=True)], axis=0)"],"metadata":{"id":"noJTxI0JPvNK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_for_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"cy0razfaSOQX","outputId":"1a903514-b68f-4cd1-fc82-6759c685bb6c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              question  \\\n","0    What is the formula for the support vector cla...   \n","1    What is the formula for calculating the Bayes ...   \n","2    What is the purpose of the tuning parameter \\(...   \n","3    How do you calculate the posterior probability...   \n","4    What is the function F(X) derived in the conte...   \n","..                                                 ...   \n","197  What is the formula for calculating the probab...   \n","198  What is the formulation of the loss function i...   \n","199  How is the variance of a dataset calculated in...   \n","200  What is the formula for approximating the func...   \n","201  What is the formula for calculating the cross-...   \n","\n","                                                answer  \n","0    The formula for the support vector classifier ...  \n","1    The formula for calculating the Bayes error ra...  \n","2    The purpose of the tuning parameter \\( \\lambda...  \n","3    The posterior probability that a given observa...  \n","4    The function F(X) derived in the context of us...  \n","..                                                 ...  \n","197  The formula for calculating the probability of...  \n","198  The relationship between the loss function L(X...  \n","199  The Proportion of Variance Explained (PVE) in ...  \n","200  The significance of the formula for the approx...  \n","201  The formula for calculating the coefficient of...  \n","\n","[243 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-c64a9b39-5eca-4373-bfbc-2d6cbb246c4e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>What is the formula for the support vector cla...</td>\n","      <td>The formula for the support vector classifier ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What is the formula for calculating the Bayes ...</td>\n","      <td>The formula for calculating the Bayes error ra...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What is the purpose of the tuning parameter \\(...</td>\n","      <td>The purpose of the tuning parameter \\( \\lambda...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>How do you calculate the posterior probability...</td>\n","      <td>The posterior probability that a given observa...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What is the function F(X) derived in the conte...</td>\n","      <td>The function F(X) derived in the context of us...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>What is the formula for calculating the probab...</td>\n","      <td>The formula for calculating the probability of...</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>What is the formulation of the loss function i...</td>\n","      <td>The relationship between the loss function L(X...</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>How is the variance of a dataset calculated in...</td>\n","      <td>The Proportion of Variance Explained (PVE) in ...</td>\n","    </tr>\n","    <tr>\n","      <th>200</th>\n","      <td>What is the formula for approximating the func...</td>\n","      <td>The significance of the formula for the approx...</td>\n","    </tr>\n","    <tr>\n","      <th>201</th>\n","      <td>What is the formula for calculating the cross-...</td>\n","      <td>The formula for calculating the coefficient of...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>243 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c64a9b39-5eca-4373-bfbc-2d6cbb246c4e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c64a9b39-5eca-4373-bfbc-2d6cbb246c4e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c64a9b39-5eca-4373-bfbc-2d6cbb246c4e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ead902bb-98a8-46d7-ba9e-1c29aaba5645\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ead902bb-98a8-46d7-ba9e-1c29aaba5645')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ead902bb-98a8-46d7-ba9e-1c29aaba5645 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"dataset_for_model","summary":"{\n  \"name\": \"dataset_for_model\",\n  \"rows\": 243,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 243,\n        \"samples\": [\n          \"What is the formula for the Bayesian Information Criterion (BIC) in the context of least squares models?\",\n          \"What is the equation for a multiple linear regression model that predicts the response variable Y based on multiple predictor variables X1, X2, \\u2026,Xp ?\",\n          \"What is the formula for calculating the log odds ratio between two classes in multinomial logistic regression using softmax coding, where the coefficients are denoted by beta?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 240,\n        \"samples\": [\n          \"Approximation of the observations in a dataset using principal components while minimizing the residual sum of squares is given by formula: Minimize A in real numbers of dimension n by M, B in real numbers of dimension p by M, equals the sum from j equals 1 to p, the sum from i equals 1 to n of the square of the difference between x sub i j and the sum from m equals 1 to M of a sub i m times b sub j m.\",\n          \"The equation for a multiple linear regression model that predicts the response variable Y based on the multiple predictor variables X1, X2, ..., Xp is given by formula: Formula -> Y is approximately equal to beta zero plus beta one times X one plus beta two times X two plus dot dot dot plus beta p times X p.\",\n          \"The relationship between the loss function and penalty term in the context of bias-variance trade-off in the formulation of a support vector classifier is described by the formula: The loss function, denoted as L of X, y, and ?, is defined as the sum over i from 1 to n (where n is the total number of observations) of the square of the difference between the observed value y sub i and the predicted value. L of X, y, and ? equals the summation over i from 1 to n of the squared difference between the actual value y sub i and the predicted value, which is the intercept ? sub 0 plus the summation over j from 1 to p of the product of x sub i j (the feature value for the ith observation and jth predictor) and ? sub j (the corresponding coefficient for the jth predictor). This whole expression is squared.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["dataset_for_model.to_csv(\"final_formuals_dataset.csv\", index=False)"],"metadata":{"id":"RphfMTkgRqvl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32mxw2lb0TY_","outputId":"ea392e81-c033-4935-ee0e-300c496109a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","dataset_for_model = pd.read_csv(\"/content/final_formuals_dataset.csv\")\n","formulas_list = dataset_for_model.to_dict(orient=\"records\")\n","q_a_dataset = [(element[\"question\"],element[\"answer\"]) for element in formulas_list]\n","full_corpus = [element[\"answer\"] for element in formulas_list]"],"metadata":{"id":"luUbXgfDZKdO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ragatouille import RAGPretrainedModel,RAGTrainer\n","\n","trainer = RAGTrainer(\n","    model_name = \"colbert-formulas-model-5\",\n","    pretrained_model_name = \"colbert-ir/colbertv2.0\"\n",")\n","\n","trainer.prepare_training_data(raw_data=q_a_dataset,\n","                              data_out_path=\"./data/\",\n","                              all_documents=full_corpus,\n","                              )\n","\n","trainer.train(batch_size = 2,\n","              dim = 128,\n","              doc_maxlen=256,\n","              use_relu = False,\n","              learning_rate=2.3e-5,\n","              nbits = 2,\n","              maxsteps=540000,\n","              )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kXTam2zmrRh","outputId":"c0fafec8-d694-4eda-af1f-ac4d629c2f44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loading Hard Negative SimpleMiner dense embedding model BAAI/bge-small-en-v1.5...\n","Building hard negative index for 240 documents...\n","All documents embedded, now adding to index...\n","save_index set to False, skipping saving hard negative index\n","Hard negative index generated\n","#> Starting...\n","#> Joined...\n"]}]},{"cell_type":"code","source":["model_path = \"/content/.ragatouille/colbert/none/2024-10/16/08.25.43/checkpoints/colbert/\"\n","\n","RAG = RAGPretrainedModel.from_pretrained(model_path)\n","\n","RAG.index(\n","    collection=full_corpus,\n","    index_name=\"colbert-formulas-index-5\",\n","    max_document_length = 256,\n","    split_documents = False,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":941},"id":"-gIceb29pTWb","outputId":"56a4af72-6074-4f48-da7a-39b3d739f4d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n","This is a behaviour change from RAGatouille 0.8.0 onwards.\n","This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n","If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n","--------------------\n","\n","\n","[Oct 16, 08:28:36] #> Creating directory .ragatouille/colbert/indexes/colbert-formulas-index-5 \n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler()\n"]},{"output_type":"stream","name":"stdout","text":["[Oct 16, 08:28:37] [0] \t\t #> Encoding 243 passages..\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"]},{"output_type":"stream","name":"stdout","text":["[Oct 16, 08:28:37] [0] \t\t avg_doclen_est = 82.60082244873047 \t len(local_sample) = 243\n","[Oct 16, 08:28:37] [0] \t\t Creating 2,048 partitions.\n","[Oct 16, 08:28:37] [0] \t\t *Estimated* 20,071 embeddings.\n","[Oct 16, 08:28:37] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/colbert-formulas-index-5/plan.json ..\n","Warning: number of training points (19069) is less than the minimum recommended (20480)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/colbert/indexing/collection_indexer.py:256: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  sub_sample = torch.load(sub_sample_path)\n"]},{"output_type":"stream","name":"stdout","text":["used 16 iterations (0.2325s) to cluster 19069 items into 2048 clusters\n","[Oct 16, 08:28:37] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n","If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[Oct 16, 08:28:38] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n","If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  centroids = torch.load(centroids_path, map_location='cpu')\n","/usr/local/lib/python3.10/dist-packages/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n","/usr/local/lib/python3.10/dist-packages/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n"]},{"output_type":"stream","name":"stdout","text":["[0.036, 0.031, 0.03, 0.033, 0.031, 0.034, 0.032, 0.03, 0.032, 0.032, 0.031, 0.033, 0.033, 0.031, 0.033, 0.032, 0.03, 0.031, 0.034, 0.031, 0.031, 0.035, 0.031, 0.035, 0.031, 0.03, 0.033, 0.031, 0.03, 0.033, 0.03, 0.028, 0.034, 0.029, 0.031, 0.029, 0.031, 0.034, 0.03, 0.037, 0.036, 0.032, 0.032, 0.031, 0.031, 0.029, 0.03, 0.038, 0.035, 0.032, 0.033, 0.032, 0.03, 0.031, 0.031, 0.036, 0.042, 0.032, 0.034, 0.033, 0.032, 0.031, 0.03, 0.034, 0.035, 0.033, 0.036, 0.032, 0.03, 0.032, 0.032, 0.035, 0.036, 0.029, 0.03, 0.034, 0.034, 0.032, 0.032, 0.035, 0.032, 0.033, 0.031, 0.033, 0.032, 0.035, 0.032, 0.035, 0.03, 0.032, 0.033, 0.032, 0.031, 0.031, 0.03, 0.031, 0.032, 0.032, 0.032, 0.031, 0.031, 0.034, 0.031, 0.033, 0.031, 0.029, 0.031, 0.032, 0.032, 0.028, 0.032, 0.035, 0.035, 0.029, 0.033, 0.031, 0.035, 0.032, 0.034, 0.03, 0.032, 0.035, 0.034, 0.034, 0.032, 0.033, 0.033, 0.032]\n"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["[Oct 16, 08:28:38] [0] \t\t #> Encoding 243 passages..\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n","1it [00:00,  1.98it/s]\n","  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(codes_path, map_location='cpu')\n","100%|██████████| 1/1 [00:00<00:00, 615.00it/s]"]},{"output_type":"stream","name":"stdout","text":["[Oct 16, 08:28:38] #> Optimizing IVF to store map from centroids to list of pids..\n","[Oct 16, 08:28:38] #> Building the emb2pid mapping..\n","[Oct 16, 08:28:38] len(emb2pid) = 20072\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 2048/2048 [00:00<00:00, 43073.08it/s]"]},{"output_type":"stream","name":"stdout","text":["[Oct 16, 08:28:38] #> Saved optimized IVF to .ragatouille/colbert/indexes/colbert-formulas-index-5/ivf.pid.pt\n","Done indexing!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["'.ragatouille/colbert/indexes/colbert-formulas-index-5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["RAG.search(\"Retrieve to me formula for support vector classifier using polynomial kernel?\")\n","#Retrieve to me formula for Multivariate Gaussian distribution.\n","#Retrieve to me formula for BIC.\n","#Retrieve to me formula for MSE (mean squared error).\n","# Retrieve to me formula for support vector classifier using polynomial kernel?\n","# Formula for the output of a neuron."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXq0AOdnp9Av","outputId":"f1b8db76-5d6b-465f-dd4b-ccae50bad614"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading searcher for index colbert-formulas-index-5 for the first time... This may take a few seconds\n","[Oct 16, 08:28:44] #> Loading codec...\n","[Oct 16, 08:28:44] #> Loading IVF...\n","[Oct 16, 08:28:44] #> Loading doclens...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler()\n","/usr/local/lib/python3.10/dist-packages/colbert/search/index_loader.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ivf, ivf_lengths = torch.load(os.path.join(self.index_path, \"ivf.pid.pt\"), map_location='cpu')\n","100%|██████████| 1/1 [00:00<00:00, 1737.49it/s]"]},{"output_type":"stream","name":"stdout","text":["[Oct 16, 08:28:44] #> Loading codes and residuals...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colbert/indexing/codecs/residual_embeddings.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(residuals_path, map_location='cpu')\n","100%|██████████| 1/1 [00:00<00:00, 492.35it/s]"]},{"output_type":"stream","name":"stdout","text":["Searcher loaded!\n","\n","#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n","#> Input: . Retrieve to me formula for support vector classifier using polynomial kernel?, \t\t True, \t\t None\n","#> Output IDs: torch.Size([32]), tensor([  101,     1, 12850,  2000,  2033,  5675,  2005,  2490,  9207,  2465,\n","        18095,  2478, 17505, 16293,  1029,   102,   103,   103,   103,   103,\n","          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n","          103,   103], device='cuda:0')\n","#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'content': 'The formula for the support vector classifier (SVC) using a polynomial kernel, as described in Equation 9.22 in the context of machine learning, is: K of x sub i and x sub i prime equals one plus the sum from j equals one to p of x sub i j times x sub i prime j, all raised to the power of d.',\n","  'score': 23.09375,\n","  'rank': 1,\n","  'document_id': '730cf306-af09-413f-bf21-e1931a51130b',\n","  'passage_id': 0},\n"," {'content': 'The formula for the support vector classifier (SVC) using a polynomial kernel, as described in Equation 9.22 in the context of machine learning, is: K of x sub i and x sub i prime equals one plus the sum from j equals one to p of x sub i j times x sub i prime j, all raised to the power of d.',\n","  'score': 23.09375,\n","  'rank': 2,\n","  'document_id': 'fc9931c8-c116-4a0e-b64a-62bbade39abf',\n","  'passage_id': 208},\n"," {'content': 'The formula for the piecewise cubic polynomial regression discussed in the section on regression splines in the machine learning book is: Formula -> y sub i equals vector p sub i0 cubed plus j sub 1 x sub i plus vector p sub 2 x sub two thirds squared plus vector p sub 1 x sub i cubed plus c sub i',\n","  'score': 15.4296875,\n","  'rank': 3,\n","  'document_id': '54696c18-77a1-4226-a890-320633769b63',\n","  'passage_id': 44},\n"," {'content': 'The significance of the exponential term in the formula for support vector machines utilizing non-linear kernels in classifying data in higher-dimensional spaces is captured by the formula: K of x sub i and x sub i prime equals the exponential of negative gamma times the sum from j equals one to p of the square of the difference between x sub i j and x sub i prime j.',\n","  'score': 14.0390625,\n","  'rank': 4,\n","  'document_id': '5ca7935d-d213-486c-afb5-ca4875d4a0e4',\n","  'passage_id': 118},\n"," {'content': 'The formula for calculating the cross-validation error using Leave-One-Out Cross-Validation (LOOCV) in machine learning, as discussed in the context of estimating mean squared error (MSE) for predicting miles per gallon (mpg) using polynomial functions of horsepower on the Auto dataset is given by: \\n\\nFormula -> C V_{<n>} = \\\\frac{1}{n} \\\\sum_{i=1}^{n} \\\\left( \\\\frac{y_{i} - \\\\hat{y}_{i}}{1 - h_{i}} \\\\right)^{2} \\n\\nSolution -> C V sub n equals 1 over n times the sum from i equals 1 to n of the quantity y sub i minus y hat sub i divided by 1 minus h sub i all squared.',\n","  'score': 13.9296875,\n","  'rank': 5,\n","  'document_id': 'b2331469-86b0-464e-979a-7292e8ca8d11',\n","  'passage_id': 46},\n"," {'content': 'The relationship between the logarithm of the odds ratio (p divided by (1 minus p)) and the polynomial terms in the logistic regression model is given by the formula: Formula -> log of (p divided by (1 minus p)) equals (Lambda zero divided by Lambda one) times X one plus beta two times X one squared plus beta three times X two plus beta four times X two squared.',\n","  'score': 13.5390625,\n","  'rank': 6,\n","  'document_id': '04801f1a-2fa5-47a4-b9ec-ca743ca215b3',\n","  'passage_id': 147},\n"," {'content': 'The formula K of x sub i and x sub i prime represents the kernel function in the context of support vector machines and kernel methods. It calculates the inner product or similarity between two data points x sub i and x sub i prime in a higher-dimensional feature space, allowing for non-linear decision boundaries and efficient computation in high-dimensional spaces.',\n","  'score': 13.46875,\n","  'rank': 7,\n","  'document_id': 'db7b8477-8a36-480d-b13e-8856b5450b9a',\n","  'passage_id': 231},\n"," {'content': \"The formula for a piecewise cubic polynomial regression with a single knot is given by:\\n\\\\[ \\\\begin{cases} \\ny = \\\\beta_0 + \\\\beta_1 x + \\\\beta_2 x^2 + \\\\beta_3 x^3 & \\\\text{if } x < k \\\\\\\\\\ny = \\\\beta_0' + \\\\beta_1' x + \\\\beta_2' x^2 + \\\\beta_3' x^3 & \\\\text{if } x \\\\geq k \\n\\\\end{cases} \\\\]\",\n","  'score': 12.84375,\n","  'rank': 8,\n","  'document_id': '6e70d9d7-7911-4011-92b9-481b067009bd',\n","  'passage_id': 119},\n"," {'content': 'The relationship between the loss function and penalty term in the context of bias-variance trade-off in the formulation of a support vector classifier is described by the formula: The loss function, denoted as L of X, y, and ?, is defined as the sum over i from 1 to n (where n is the total number of observations) of the square of the difference between the observed value y sub i and the predicted value. L of X, y, and ? equals the summation over i from 1 to n of the squared difference between the actual value y sub i and the predicted value, which is the intercept ? sub 0 plus the summation over j from 1 to p of the product of x sub i j (the feature value for the ith observation and jth predictor) and ? sub j (the corresponding coefficient for the jth predictor). This whole expression is squared.',\n","  'score': 12.78125,\n","  'rank': 9,\n","  'document_id': '941034ad-97ac-4656-9545-1fa6c974848b',\n","  'passage_id': 94},\n"," {'content': 'The relationship between the loss function L(X, y, beta) and the penalty term in the context of bias-variance trade-off in the formulation of a support vector classifier is described by the formula: The loss function L of X, y, and beta is equal to the summation over i from 1 to n of the maximum value between 0 and 1 minus y sub i multiplied by the expression beta sub 0 plus beta sub 1 times x sub i1 plus up to beta sub p times x sub ip, where n is the number of data points, y sub i represents the target value for the ith observation, beta sub 0 is the intercept, beta sub 1 to beta sub p are the coefficients for the corresponding features x sub i1 to x sub ip of the ith observation, and the max function ensures that only positive values contribute to the sum.',\n","  'score': 12.734375,\n","  'rank': 10,\n","  'document_id': 'e5e19a67-a645-4b67-9282-fa84ea2954ef',\n","  'passage_id': 239}]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["%cp -r /content/.ragatouille/colbert/none/2024-10/16/08.25.43/checkpoints/colbert/ /content/drive/MyDrive/project_work/code/formulas_retrieval/FormulasColBERTCheckpointsFinal/"],"metadata":{"id":"lJE6xp6wz3k6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cp -r /content/.ragatouille/colbert/indexes/colbert-formulas-index-5/ /content/drive/MyDrive/project_work/code/formulas_retrieval/FormulasColBERTIndexFinal/"],"metadata":{"id":"O8Civllb04H3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Korpus**"],"metadata":{"id":"pUAN-biq2YoK"}},{"cell_type":"code","source":["corpus_dict = dict()\n","\n","for key, val in RAG.model.__dict__['pid_docid_map'].items():\n","  pid = key\n","  corpus_dict[str(val)] = {\"text\":full_corpus[pid], \"title\":\"\"}"],"metadata":{"id":"4TZoiWOC1t64"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**List of queries**"],"metadata":{"id":"pVRpiqpA2e_E"}},{"cell_type":"code","source":["queries = {str(ind):q for ind, q in enumerate(dataset_for_model[\"question\"]) }"],"metadata":{"id":"8VLEWCLH2fIx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_doc_id(element:str, corpus:dict):\n","  for key, val in corpus.items():\n","    if val[\"text\"] == element:\n","      return key\n","\n","answer_doc_ids = [find_doc_id(desc,corpus_dict) for desc in dataset_for_model[\"answer\"] ]"],"metadata":{"id":"C1SaL9VB20aK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Qrels dictionary**"],"metadata":{"id":"YLMh-QIW3Eqg"}},{"cell_type":"code","source":["qrels_dict = dict()\n","\n","qrels_dict = {str(question_id):{str(document_id):1} for question_id, document_id in zip(list(queries.keys()),answer_doc_ids)} # '0', 'sdhaisdhasdkj'"],"metadata":{"id":"Ur5eu8dW3E3V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Pretraga na trening skupu**"],"metadata":{"id":"zbgB-BjT3PVV"}},{"cell_type":"code","source":["search_results = RAG.search(list(queries.values()),k=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4tw5S3G3RJj","outputId":"09ff4ccf-81a0-4e03-d9e8-4ac0b0cc4ba1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["243it [00:01, 124.91it/s]\n"]}]},{"cell_type":"code","source":["def normalize_data(search_results):\n","  normalized_scores = dict()\n","  max_score = search_results[0][\"score\"]\n","  min_score = search_results[-1][\"score\"]\n","  for result in search_results:\n","    norm_score = (result[\"score\"] - min_score) / (max_score - min_score + 1e-10)\n","    normalized_scores[str(result[\"document_id\"])] = norm_score\n","  return normalized_scores\n","scores = normalize_data(search_results[0])"],"metadata":{"id":"R-gnXsGY3T8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_of_retrieval = dict()\n","for query_id, query_results in zip(list(queries.keys()), search_results):\n","  results_of_retrieval[str(query_id)] = normalize_data(query_results)"],"metadata":{"id":"yJFHySfJ3Zwm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Evaluacija**"],"metadata":{"id":"zeyR1qqK3c2A"}},{"cell_type":"code","source":["!pip install beir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"zSfzwfo53lGP","outputId":"ebad5909-c797-4db8-ae24-866a0f3a880b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: beir in /usr/local/lib/python3.10/dist-packages (2.0.0)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from beir) (2.7.0)\n","Requirement already satisfied: pytrec-eval in /usr/local/lib/python3.10/dist-packages (from beir) (0.5)\n","Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from beir) (1.9.0)\n","Requirement already satisfied: elasticsearch==7.9.1 in /usr/local/lib/python3.10/dist-packages (from beir) (7.9.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from beir) (3.0.1)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2.2.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->beir) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.10.10)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (6.0.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (4.44.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (2.4.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.13.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (10.4.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.14.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets->beir) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->beir) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->beir) (3.10)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->beir) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->beir) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->beir) (3.1.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->beir) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->beir) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers->beir) (0.19.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->beir) (2024.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->beir) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->beir) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->beir) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->beir) (0.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers->beir) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers->beir) (1.3.0)\n"]}]},{"cell_type":"code","source":["from beir.retrieval.evaluation import EvaluateRetrieval\n","ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(qrels_dict, results_of_retrieval, k_values=[1, 3, 5, 10])"],"metadata":{"id":"XkuPag_B3eGW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(_map)\n","print(recall)\n","print(precision)\n","print(ndcg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lPnwWxyt3jWk","outputId":"23ccd13f-e304-4773-e419-a01e614ca6a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'MAP@1': 0.84362, 'MAP@3': 0.90466, 'MAP@5': 0.90775, 'MAP@10': 0.9088}\n","{'Recall@1': 0.84362, 'Recall@3': 0.97531, 'Recall@5': 0.98765, 'Recall@10': 0.99588}\n","{'P@1': 0.84362, 'P@3': 0.3251, 'P@5': 0.19753, 'P@10': 0.09959}\n","{'NDCG@1': 0.84362, 'NDCG@3': 0.92294, 'NDCG@5': 0.92825, 'NDCG@10': 0.93086}\n"]}]}]}